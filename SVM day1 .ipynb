{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e677a766-3aa4-43a5-bca2-f21747bad7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abe08b8a-1828-434c-a15b-277984d45570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM (Support Vector Machine) ----->svm is a sml algo that is use for both Classification and Regression task it is particularly in dealing with\n",
    "# complex and high dimensional data set.\n",
    "# the fundamental principle of svm is to find and optimal hyperplain that maximize separate diffent classes in the input space \n",
    "\n",
    "# how svm work \n",
    "# 1. first of all we will prepare our dataset \n",
    "# 2. svm require label training data consistance of input feature and corresponding class label than \n",
    "# 3. each data point is represented as a feature vector where is feature describe a perticular characteristic of the data point \n",
    "# 4. the datapoint should be preprocess and scaled to ensure the feature are on simmilar scale typically between 0 and 1  \n",
    "\n",
    "# Hyperplain And Margin\n",
    "# Svm aims to find a HP that based sep.. the different classes in the feature space . in a binary classification prob. the hyperplain is a line \n",
    "# in a 2D space or in a higher Dimensional space \n",
    "# SVM seeks to maximize the margin which is the distance between the HP and the nearest dP  from each class .. the points in the margin are known as\n",
    "# SV. as they play a crucial role in defining the dicision boundary \n",
    "\n",
    "# Linear SVM the linear svm finds a L HP that sep the classes. The goal is to find the HP that max. the margin while Min the misclassification of trainming example \n",
    "# Mathematical this can be formulated as an optimization problem with the objective of Min. the wights of the HP \n",
    "# Subject to the contrix that all training eg. lie on the correct side of the HP  \n",
    "\n",
    "# Non- Linear SVM \n",
    "# in cases where data  is non linear seperable svm using a technique called the kernal trick. \n",
    "# the keranal trick map the original input sapce intol a higher dimensional \n",
    "# feature space where the datapoints can be linearly seperable \n",
    "# the choice of the kernal depends on the characteristic of the data and the probl at hand \n",
    "\n",
    "# Trining of Svm \n",
    "# svm training involves finding the optimal hp or decision boundary that seprate the classes the optimization prob is typically solve using method \n",
    "# such as quadratic programing or sequencial minimal optimization the process involvessolving for the weight of the Hp \n",
    "# and the bayes term which define the Decision boundary \n",
    "# the objective is to minimize the regularizATION Term while ensuring that the training eg are correctly classify \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec85781-cf8a-4f0f-bd55-78775ceb750e",
   "metadata": {},
   "source": [
    "# SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "428781e1-2587-4d36-bc05-165070ea56a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM (Support Vector Machine)\n",
    "# SVM is a supervised machine learning algorithm that is used for both classification and regression tasks.\n",
    "# It is particularly effective in dealing with complex and high-dimensional datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb6e6190-3c80-4e9c-a857-03f9f99442d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fundamental principle of SVM is to find an optimal hyperplane that maximally separates different classes in the input space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bea2f52-3b10-45dc-870f-b4da80c5d2b5",
   "metadata": {},
   "source": [
    "# How SVM Works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "876d40bf-2b61-43f6-8e32-e524f23c1274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. First, we prepare our dataset.\n",
    "# 2. SVM requires labeled training data consisting of input features and corresponding class labels.\n",
    "# 3. Each data point is represented as a feature vector, where each feature describes a particular characteristic of the data point.\n",
    "# 4. The data points should be preprocessed and scaled to ensure the features are on a similar scale, typically between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf64bc1-6264-411d-b8fb-6c546dd2d2d9",
   "metadata": {},
   "source": [
    "# Hyperplane and Margin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1194b80-170a-465b-834b-56efe726122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM aims to find a hyperplane that best separates the different classes in the feature space.\n",
    "# In a binary classification problem, the hyperplane is a line in 2D space or a plane/hyperplane in higher-dimensional space.\n",
    "# SVM seeks to maximize the margin, which is the distance between the hyperplane and the nearest data points from each class.\n",
    "# These nearest data points are known as Support Vectors, as they play a crucial role in defining the decision boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c994f65-6065-4f5e-b89a-8ac5223a4b25",
   "metadata": {},
   "source": [
    "# Linear SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa8ed56b-869c-4618-9e87-ba6457e85607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The linear SVM finds a linear hyperplane that separates the classes.\n",
    "# The goal is to find the hyperplane that maximizes the margin while minimizing the misclassification of training examples.\n",
    "# Mathematically, this can be formulated as an optimization problem with the objective of minimizing the weights of the hyperplane,\n",
    "# subject to the constraint that all training examples lie on the correct side of the hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb120d-1e85-4faf-b841-66ef90b1403b",
   "metadata": {},
   "source": [
    "# Non-Linear SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05d65c83-35bf-4d1c-a1dd-5cf229f75235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In cases where data is not linearly separable, SVM uses a technique called the \"kernel trick\".\n",
    "# The kernel trick maps the original input space into a higher-dimensional feature space,\n",
    "# where the data points can be linearly separable.\n",
    "# The choice of the kernel depends on the characteristics of the data and the problem at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e705cc3e-3a83-45fc-b71a-ee1ce6b0495c",
   "metadata": {},
   "source": [
    "# Training of SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8609dcf2-e3de-4ea8-82b1-4a8b82d7b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM training involves finding the optimal hyperplane or decision boundary that separates the classes.\n",
    "# The optimization problem is typically solved using methods such as Quadratic Programming or Sequential Minimal Optimization (SMO).\n",
    "# The process involves solving for the weights of the hyperplane and the bias term, which together define the decision boundary.\n",
    "# The objective is to minimize the regularization term while ensuring that the training examples are correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73f8556-a21f-4f3f-b128-a84217e46488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
